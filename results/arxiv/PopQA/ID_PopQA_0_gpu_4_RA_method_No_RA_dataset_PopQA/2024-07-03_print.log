2024-07-03 11:37:15,474 **************** Configuration **************** 
2024-07-03 11:37:15,475 gpu: 4
2024-07-03 11:37:15,475 test_code_flag: False
2024-07-03 11:37:15,475 ID: PopQA_0
2024-07-03 11:37:15,475 seed: 42
2024-07-03 11:37:15,475 num_workers: 48
2024-07-03 11:37:15,475 loading_ckpt_path: None
2024-07-03 11:37:15,475 RA_method: No_RA
2024-07-03 11:37:15,475 LLM: meta-llama/Meta-Llama-3-8B-Instruct
2024-07-03 11:37:15,475 dataset: PopQA
2024-07-03 11:37:15,475 train_batch_size: 2
2024-07-03 11:37:15,475 test_batch_size: 2
2024-07-03 11:37:15,475 accumulation_steps: 1
2024-07-03 11:37:15,475 demonstration: False
2024-07-03 11:37:15,475 demons_cnt: 1
2024-07-03 11:37:15,475 l2_coef: 0
2024-07-03 11:37:15,475 train_eval: 500
2024-07-03 11:37:15,475 total_step: 25000
2024-07-03 11:37:15,475 gate_weight: 2
2024-07-03 11:37:15,475 lr: 0.0001
2024-07-03 11:37:15,475 init_lr_num: 500
2024-07-03 11:37:15,475 lr_decay: 0.9
2024-07-03 11:37:15,475 lr_decay_interval: 400
2024-07-03 11:37:15,475 num_layers: 1
2024-07-03 11:37:15,476 d_model: 768
2024-07-03 11:37:15,476 dim_feedforward: 2048
2024-07-03 11:37:15,476 layer_norm_eps: 1e-05
2024-07-03 11:37:15,476 nhead: 8
2024-07-03 11:37:15,476 dropout: 0.1
2024-07-03 11:37:15,476 loss_list: kl_soft+kl_hard
2024-07-03 11:37:15,476 len_penalty_weight: 10
2024-07-03 11:37:15,476 soft_weight: 1
2024-07-03 11:37:15,476 hard_weight: 1
2024-07-03 11:37:15,476 do_sample: True
2024-07-03 11:37:15,476 temperature: 1e-09
2024-07-03 11:37:15,476 top_p: 0
2024-07-03 11:37:15,476 max_new_tokens: 40
2024-07-03 11:37:15,476 infer_add_gold_retrieval: False
2024-07-03 11:37:15,476 multi_query: False
2024-07-03 11:37:15,476 rewrite_num: 1
2024-07-03 11:37:15,476 chunk_size: 512
2024-07-03 11:37:15,476 chunk_overlap: 20
2024-07-03 11:37:15,476 if_hierarchical_retrieval: True
2024-07-03 11:37:15,476 hierarchical_ratio: 1.4
2024-07-03 11:37:15,476 quantile_num: 0.99
2024-07-03 11:37:15,476 n_docs: 10
2024-07-03 11:37:15,476 model_name_or_path: facebook/contriever-msmarco
2024-07-03 11:37:15,476 question_maxlength: 512
2024-07-03 11:37:15,476 passages: datasets/Retrieval_corpus/enwiki_2020_dec_intro_only.jsonl
2024-07-03 11:37:15,476 passages_embeddings: datasets/Retrieval_corpus/enwiki_dec_2020_contriever_intro/*
2024-07-03 11:37:15,476 lowercase: False
2024-07-03 11:37:15,477 normalize_text: False
2024-07-03 11:37:15,477 save_or_load_index: False
2024-07-03 11:37:15,477 no_fp16: True
2024-07-03 11:37:15,477 projection_size: 768
2024-07-03 11:37:15,477 n_subquantizers: 0
2024-07-03 11:37:15,477 n_bits: 8
2024-07-03 11:37:15,477 indexing_batch_size: 30000000
2024-07-03 11:37:15,477 device: cuda
2024-07-03 11:37:15,477 prompt_file: prompts/PopQA.json
2024-07-03 11:37:15,477 dir_path: ./results/output/ID_PopQA_0_gpu_4_RA_method_No_RA_dataset_PopQA
2024-07-03 11:37:15,477 print_logger: <Logger print (DEBUG)>
2024-07-03 11:37:15,477 **************** Configuration **************** 


2024-07-03 11:37:15,477 Loading meta-llama/Meta-Llama-3-8B-Instruct in torch.bfloat16...
2024-07-03 11:37:22,705 Finish loading in 0.12 mins.
2024-07-03 11:37:23,258 Loading data ...
2024-07-03 11:37:23,348 prompt_format: general-prompt 

2024-07-03 11:37:23,348 
 Start test ...  
2024-07-03 11:37:26,093 testing process num: 0
2024-07-03 11:41:20,549 testing process num: 200
2024-07-03 11:45:09,514 testing process num: 400
2024-07-03 11:48:57,943 testing process num: 600
2024-07-03 11:51:08,027 test: f1 28.15, EM : 22.92, old_doc_len:0.0, new_doc_len:0.0
2024-07-03 11:51:08,028 cost_time: 13.744656825065613  
 
