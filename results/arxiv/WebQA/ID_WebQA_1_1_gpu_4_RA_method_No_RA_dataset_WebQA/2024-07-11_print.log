2024-07-11 15:24:50,096 **************** Configuration **************** 
2024-07-11 15:24:50,097 gpu: 4
2024-07-11 15:24:50,097 test_code_flag: False
2024-07-11 15:24:50,097 ID: WebQA_1_1
2024-07-11 15:24:50,097 seed: 42
2024-07-11 15:24:50,097 num_workers: 48
2024-07-11 15:24:50,097 loading_ckpt_path: None
2024-07-11 15:24:50,097 RA_method: No_RA
2024-07-11 15:24:50,097 LLM: meta-llama/Meta-Llama-3-8B-Instruct
2024-07-11 15:24:50,097 dataset: WebQA
2024-07-11 15:24:50,097 train_batch_size: 8
2024-07-11 15:24:50,097 test_batch_size: 8
2024-07-11 15:24:50,097 accumulation_steps: 1
2024-07-11 15:24:50,097 demonstration: False
2024-07-11 15:24:50,097 demons_cnt: 1
2024-07-11 15:24:50,097 l2_coef: 0
2024-07-11 15:24:50,097 train_eval: 500
2024-07-11 15:24:50,097 total_step: 25000
2024-07-11 15:24:50,097 gate_weight_0: 1
2024-07-11 15:24:50,097 gate_weight_1: 2
2024-07-11 15:24:50,097 lr: 0.0001
2024-07-11 15:24:50,097 init_lr_num: 500
2024-07-11 15:24:50,097 lr_decay: 0.9
2024-07-11 15:24:50,097 lr_decay_interval: 400
2024-07-11 15:24:50,097 num_layers: 1
2024-07-11 15:24:50,097 d_model: 768
2024-07-11 15:24:50,097 dim_feedforward: 2048
2024-07-11 15:24:50,097 layer_norm_eps: 1e-05
2024-07-11 15:24:50,097 nhead: 8
2024-07-11 15:24:50,097 dropout: 0.1
2024-07-11 15:24:50,097 loss_list: kl_soft+kl_hard
2024-07-11 15:24:50,097 len_penalty_weight: 10
2024-07-11 15:24:50,097 soft_weight: 1
2024-07-11 15:24:50,098 hard_weight: 1
2024-07-11 15:24:50,098 do_sample: True
2024-07-11 15:24:50,098 temperature: 1e-09
2024-07-11 15:24:50,098 top_p: 0
2024-07-11 15:24:50,098 max_new_tokens: 40
2024-07-11 15:24:50,098 infer_add_gold_retrieval: False
2024-07-11 15:24:50,098 multi_query: False
2024-07-11 15:24:50,098 rewrite_num: 1
2024-07-11 15:24:50,098 chunk_size: 512
2024-07-11 15:24:50,098 chunk_overlap: 20
2024-07-11 15:24:50,098 if_hierarchical_retrieval: True
2024-07-11 15:24:50,098 hierarchical_ratio: 1.4
2024-07-11 15:24:50,098 quantile_num: 1
2024-07-11 15:24:50,098 n_docs: 10
2024-07-11 15:24:50,098 model_name_or_path: facebook/contriever-msmarco
2024-07-11 15:24:50,098 question_maxlength: 512
2024-07-11 15:24:50,098 passages: datasets/Retrieval_corpus/enwiki_2020_dec_intro_only.jsonl
2024-07-11 15:24:50,098 passages_embeddings: datasets/Retrieval_corpus/enwiki_dec_2020_contriever_intro/*
2024-07-11 15:24:50,098 lowercase: False
2024-07-11 15:24:50,098 normalize_text: False
2024-07-11 15:24:50,098 save_or_load_index: False
2024-07-11 15:24:50,098 no_fp16: True
2024-07-11 15:24:50,098 projection_size: 768
2024-07-11 15:24:50,098 n_subquantizers: 0
2024-07-11 15:24:50,098 n_bits: 8
2024-07-11 15:24:50,098 indexing_batch_size: 30000000
2024-07-11 15:24:50,098 device: cuda
2024-07-11 15:24:50,098 prompt_file: prompts/WebQA.json
2024-07-11 15:24:50,098 dir_path: ./results/output/ID_WebQA_1_1_gpu_4_RA_method_No_RA_dataset_WebQA
2024-07-11 15:24:50,098 print_logger: <Logger print (DEBUG)>
2024-07-11 15:24:50,098 **************** Configuration **************** 


2024-07-11 15:24:50,098 Loading meta-llama/Meta-Llama-3-8B-Instruct in torch.bfloat16...
2024-07-11 15:24:55,860 Finish loading in 0.10 mins.
2024-07-11 15:24:56,385 Loading data ...
2024-07-11 15:24:56,398 prompt_format: general-prompt 

2024-07-11 15:24:56,398 
 Start test ...  
2024-07-11 15:24:58,493 testing process num: 0
2024-07-11 15:28:51,828 testing process num: 200
2024-07-11 15:29:54,987 test: f1 27.83, EM : 46.01, old_doc_len:0.0, new_doc_len:0.0
2024-07-11 15:29:54,988 cost_time: 4.976489384969075  
 
