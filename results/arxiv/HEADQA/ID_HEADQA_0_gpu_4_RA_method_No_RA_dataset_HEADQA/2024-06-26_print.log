2024-06-26 19:05:23,598 **************** Configuration **************** 
2024-06-26 19:05:23,599 gpu: 4
2024-06-26 19:05:23,599 test_code_flag: False
2024-06-26 19:05:23,599 ID: HEADQA_0
2024-06-26 19:05:23,599 seed: 42
2024-06-26 19:05:23,599 num_workers: 48
2024-06-26 19:05:23,599 loading_ckpt_path: None
2024-06-26 19:05:23,599 RA_method: No_RA
2024-06-26 19:05:23,599 LLM: meta-llama/Meta-Llama-3-8B-Instruct
2024-06-26 19:05:23,599 dataset: HEADQA
2024-06-26 19:05:23,599 train_batch_size: 2
2024-06-26 19:05:23,599 test_batch_size: 2
2024-06-26 19:05:23,599 accumulation_steps: 1
2024-06-26 19:05:23,599 demonstration: False
2024-06-26 19:05:23,599 demons_cnt: 1
2024-06-26 19:05:23,599 l2_coef: 0
2024-06-26 19:05:23,599 train_eval: 500
2024-06-26 19:05:23,599 epoch: 20
2024-06-26 19:05:23,599 gate_weight: 2
2024-06-26 19:05:23,599 lr: 0.0001
2024-06-26 19:05:23,599 init_lr_num: 500
2024-06-26 19:05:23,599 lr_decay: 0.9
2024-06-26 19:05:23,599 lr_decay_interval: 400
2024-06-26 19:05:23,599 num_layers: 1
2024-06-26 19:05:23,599 d_model: 768
2024-06-26 19:05:23,600 dim_feedforward: 2048
2024-06-26 19:05:23,600 layer_norm_eps: 1e-05
2024-06-26 19:05:23,600 nhead: 8
2024-06-26 19:05:23,600 dropout: 0.1
2024-06-26 19:05:23,600 loss_list: kl_soft+kl_hard
2024-06-26 19:05:23,600 len_penalty_weight: 10
2024-06-26 19:05:23,600 soft_weight: 1
2024-06-26 19:05:23,600 hard_weight: 1
2024-06-26 19:05:23,600 do_sample: True
2024-06-26 19:05:23,600 temperature: 1e-09
2024-06-26 19:05:23,600 top_p: 0
2024-06-26 19:05:23,600 max_new_tokens: 1
2024-06-26 19:05:23,600 infer_add_gold_retrieval: False
2024-06-26 19:05:23,600 multi_query: False
2024-06-26 19:05:23,600 rewrite_num: 1
2024-06-26 19:05:23,600 chunk_size: 512
2024-06-26 19:05:23,600 chunk_overlap: 20
2024-06-26 19:05:23,600 if_hierarchical_retrieval: True
2024-06-26 19:05:23,600 hierarchical_ratio: 1.4
2024-06-26 19:05:23,600 quantile_num: 0.99
2024-06-26 19:05:23,600 n_docs: 10
2024-06-26 19:05:23,600 model_name_or_path: facebook/contriever-msmarco
2024-06-26 19:05:23,600 question_maxlength: 512
2024-06-26 19:05:23,600 passages: datasets/Retrieval_corpus/enwiki_2020_dec_intro_only.jsonl
2024-06-26 19:05:23,600 passages_embeddings: datasets/Retrieval_corpus/enwiki_dec_2020_contriever_intro/*
2024-06-26 19:05:23,600 lowercase: False
2024-06-26 19:05:23,600 normalize_text: False
2024-06-26 19:05:23,600 save_or_load_index: False
2024-06-26 19:05:23,601 no_fp16: True
2024-06-26 19:05:23,601 projection_size: 768
2024-06-26 19:05:23,601 n_subquantizers: 0
2024-06-26 19:05:23,601 n_bits: 8
2024-06-26 19:05:23,601 indexing_batch_size: 30000000
2024-06-26 19:05:23,601 device: cuda
2024-06-26 19:05:23,601 prompt_file: prompts/HEADQA.json
2024-06-26 19:05:23,601 dir_path: ./results/output/ID_HEADQA_0_gpu_4_RA_method_No_RA_dataset_HEADQA
2024-06-26 19:05:23,601 print_logger: <Logger print (DEBUG)>
2024-06-26 19:05:23,601 **************** Configuration **************** 


2024-06-26 19:05:23,601 Loading meta-llama/Meta-Llama-3-8B-Instruct in torch.bfloat16...
2024-06-26 19:05:31,347 Finish loading in 0.13 mins.
2024-06-26 19:05:31,932 Loading data ...
2024-06-26 19:05:32,085 prompt_format: general-prompt 

2024-06-26 19:05:32,086 
 Start test ...  
2024-06-26 19:05:35,834 testing process num: 0
2024-06-26 19:05:45,403 testing process num: 200
2024-06-26 19:05:54,488 testing process num: 400
2024-06-26 19:06:03,429 testing process num: 600
2024-06-26 19:06:11,306 testing process num: 800
2024-06-26 19:06:19,865 testing process num: 1000
2024-06-26 19:06:40,712 testing process num: 1200
2024-06-26 19:06:58,740 test: acc 55.8, f1 55.17, precision 55.47, recall 58.0, old_doc_len:0.0, new_doc_len:0.0, hallucination: 11.01 
2024-06-26 19:06:58,740 cost_time: 1.4442263086636862  
 
