2024-06-27 13:28:54,976 **************** Configuration **************** 
2024-06-27 13:28:54,976 gpu: 7
2024-06-27 13:28:54,976 test_code_flag: False
2024-06-27 13:28:54,976 ID: MedMCQA_1
2024-06-27 13:28:54,976 seed: 42
2024-06-27 13:28:54,976 num_workers: 48
2024-06-27 13:28:54,976 loading_ckpt_path: None
2024-06-27 13:28:54,976 RA_method: No_RA
2024-06-27 13:28:54,976 LLM: meta-llama/Meta-Llama-3-8B-Instruct
2024-06-27 13:28:54,976 dataset: MedMCQA
2024-06-27 13:28:54,976 train_batch_size: 2
2024-06-27 13:28:54,976 test_batch_size: 2
2024-06-27 13:28:54,976 accumulation_steps: 1
2024-06-27 13:28:54,976 demonstration: False
2024-06-27 13:28:54,977 demons_cnt: 1
2024-06-27 13:28:54,977 l2_coef: 0
2024-06-27 13:28:54,977 train_eval: 500
2024-06-27 13:28:54,977 epoch: 10
2024-06-27 13:28:54,977 gate_weight: 2
2024-06-27 13:28:54,977 lr: 0.0001
2024-06-27 13:28:54,977 init_lr_num: 500
2024-06-27 13:28:54,977 lr_decay: 0.9
2024-06-27 13:28:54,977 lr_decay_interval: 400
2024-06-27 13:28:54,977 num_layers: 1
2024-06-27 13:28:54,977 d_model: 768
2024-06-27 13:28:54,977 dim_feedforward: 2048
2024-06-27 13:28:54,977 layer_norm_eps: 1e-05
2024-06-27 13:28:54,977 nhead: 8
2024-06-27 13:28:54,977 dropout: 0.1
2024-06-27 13:28:54,977 loss_list: kl_soft+kl_hard
2024-06-27 13:28:54,977 len_penalty_weight: 10
2024-06-27 13:28:54,977 soft_weight: 1
2024-06-27 13:28:54,977 hard_weight: 1
2024-06-27 13:28:54,977 do_sample: True
2024-06-27 13:28:54,977 temperature: 1e-09
2024-06-27 13:28:54,977 top_p: 0
2024-06-27 13:28:54,977 max_new_tokens: 1
2024-06-27 13:28:54,977 infer_add_gold_retrieval: False
2024-06-27 13:28:54,977 multi_query: False
2024-06-27 13:28:54,977 rewrite_num: 1
2024-06-27 13:28:54,978 chunk_size: 512
2024-06-27 13:28:54,978 chunk_overlap: 20
2024-06-27 13:28:54,978 if_hierarchical_retrieval: True
2024-06-27 13:28:54,978 hierarchical_ratio: 1.4
2024-06-27 13:28:54,978 quantile_num: 0.99
2024-06-27 13:28:54,978 n_docs: 10
2024-06-27 13:28:54,978 model_name_or_path: facebook/contriever-msmarco
2024-06-27 13:28:54,978 question_maxlength: 512
2024-06-27 13:28:54,978 passages: datasets/Retrieval_corpus/enwiki_2020_dec_intro_only.jsonl
2024-06-27 13:28:54,978 passages_embeddings: datasets/Retrieval_corpus/enwiki_dec_2020_contriever_intro/*
2024-06-27 13:28:54,978 lowercase: False
2024-06-27 13:28:54,978 normalize_text: False
2024-06-27 13:28:54,978 save_or_load_index: False
2024-06-27 13:28:54,978 no_fp16: True
2024-06-27 13:28:54,978 projection_size: 768
2024-06-27 13:28:54,978 n_subquantizers: 0
2024-06-27 13:28:54,978 n_bits: 8
2024-06-27 13:28:54,978 indexing_batch_size: 30000000
2024-06-27 13:28:54,978 device: cuda
2024-06-27 13:28:54,978 prompt_file: prompts/MedMCQA.json
2024-06-27 13:28:54,978 dir_path: ./results/output/ID_MedMCQA_1_gpu_7_epoch_10_RA_method_No_RA_dataset_MedMCQA
2024-06-27 13:28:54,978 print_logger: <Logger print (DEBUG)>
2024-06-27 13:28:54,978 **************** Configuration **************** 


2024-06-27 13:28:54,978 Loading meta-llama/Meta-Llama-3-8B-Instruct in torch.bfloat16...
2024-06-27 13:29:01,912 Finish loading in 0.12 mins.
2024-06-27 13:29:02,464 Loading data ...
2024-06-27 13:29:02,566 prompt_format: general-prompt 

2024-06-27 13:29:02,566 
 Start test ...  
2024-06-27 13:29:06,283 testing process num: 0
2024-06-27 13:29:15,364 testing process num: 200
2024-06-27 13:29:23,102 testing process num: 400
2024-06-27 13:29:30,810 testing process num: 600
2024-06-27 13:29:38,492 testing process num: 800
2024-06-27 13:29:46,151 testing process num: 1000
2024-06-27 13:29:53,810 testing process num: 1200
2024-06-27 13:30:01,483 testing process num: 1400
2024-06-27 13:30:09,147 testing process num: 1600
2024-06-27 13:30:16,822 testing process num: 1800
2024-06-27 13:30:24,492 testing process num: 2000
2024-06-27 13:30:28,239 test: acc 47.57, f1 45.69, precision 45.59, recall 50.54, old_doc_len:0.0, new_doc_len:0.0, hallucination: 4.85 
2024-06-27 13:30:28,239 cost_time: 1.4278858025868735  
 
